{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'explore/treated_data_complete.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mexplore/treated_data_complete.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pytorch/lib/python3.10/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pytorch/lib/python3.10/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pytorch/lib/python3.10/site-packages/pandas/io/parsers/readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    947\u001b[0m )\n\u001b[1;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pytorch/lib/python3.10/site-packages/pandas/io/parsers/readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    602\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    604\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 605\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pytorch/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1439\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pytorch/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1734\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1735\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1736\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1737\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1738\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1739\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1740\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1741\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1742\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1743\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1744\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pytorch/lib/python3.10/site-packages/pandas/io/common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    851\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    852\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    853\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    854\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    855\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 856\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    863\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    864\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    865\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'explore/treated_data_complete.csv'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('explore/treated_data_complete.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P0\n",
      "P1_a\n",
      "P1_a_1\n",
      "P1_b\n",
      "P1_c\n",
      "P1_d\n",
      "P1_e\n",
      "P1_e_1\n",
      "P1_e_2\n",
      "P1_e_3\n",
      "P1_e_4\n",
      "P1_f\n",
      "P1_f_1\n",
      "P1_f_2\n",
      "P1_f_3\n",
      "P1_f_4\n",
      "P1_f_5\n",
      "P1_f_6\n",
      "P1_f_7\n",
      "P1_f_8\n",
      "P1_f_9\n",
      "P1_g\n",
      "P1_i\n",
      "P1_i_1\n",
      "P1_i_2\n",
      "P1_j\n",
      "P1_k\n",
      "P1_l\n",
      "P1_m\n",
      "P2_a\n",
      "P2_b\n",
      "P2_c\n",
      "P2_d\n",
      "P2_e\n",
      "P2_f\n",
      "P2_g\n",
      "P2_h\n",
      "P2_i\n",
      "P2_j\n",
      "P2_k\n",
      "P2_l\n",
      "P2_l_1\n",
      "P2_l_2\n",
      "P2_l_3\n",
      "P2_l_4\n",
      "P2_l_5\n",
      "P2_l_6\n",
      "P2_l_7\n",
      "P2_m\n",
      "P2_n\n",
      "P2_o\n",
      "P2_o_1\n",
      "P2_o_2\n",
      "P2_o_3\n",
      "P2_o_4\n",
      "P2_o_5\n",
      "P2_o_6\n",
      "P2_o_7\n",
      "P2_o_8\n",
      "P2_o_9\n",
      "P2_o_10\n",
      "P2_q\n",
      "P2_r\n",
      "P2_s\n",
      "P2_t\n",
      "P2_o(List)\n",
      "P2_o_1(FromList)\n",
      "P2_o_2(FromList)\n",
      "P2_o_3(FromList)\n",
      "P2_o_4(FromList)\n",
      "P2_o_5(FromList)\n",
      "P2_o_6(FromList)\n",
      "P2_o_7(FromList)\n",
      "P2_o_8(FromList)\n",
      "P2_o_9(FromList)\n",
      "P2_o_10(FromList)\n",
      "P1_l_Doutorado ou Phd(OneHot)\n",
      "P1_l_Estudante de Graduação(OneHot)\n",
      "P1_l_Graduação/Bacharelado(OneHot)\n",
      "P1_l_Mestrado(OneHot)\n",
      "P1_l_Não tenho graduação formal(OneHot)\n",
      "P1_l_Prefiro não informar(OneHot)\n",
      "P1_l_Pós-graduação(OneHot)\n",
      "P1_m_Ciências Biológicas/ Farmácia/ Medicina/ Área da Saúde(OneHot)\n",
      "P1_m_Ciências Sociais(OneHot)\n",
      "P1_m_Computação / Engenharia de Software / Sistemas de Informação/ TI(OneHot)\n",
      "P1_m_Economia/ Administração / Contabilidade / Finanças/ Negócios(OneHot)\n",
      "P1_m_Estatística/ Matemática / Matemática Computacional/ Ciências Atuariais(OneHot)\n",
      "P1_m_Marketing / Publicidade / Comunicação / Jornalismo(OneHot)\n",
      "P1_m_Outra opção(OneHot)\n",
      "P1_m_Outras Engenharias(OneHot)\n",
      "P1_m_Química / Física(OneHot)\n",
      "P1_m_nan(OneHot)\n",
      "P2_b_Agronegócios(OneHot)\n",
      "P2_b_Educação(OneHot)\n",
      "P2_b_Entretenimento ou Esportes(OneHot)\n",
      "P2_b_Filantropia/ONG's(OneHot)\n",
      "P2_b_Finanças ou Bancos(OneHot)\n",
      "P2_b_Indústria(OneHot)\n",
      "P2_b_Internet/Ecommerce(OneHot)\n",
      "P2_b_Marketing(OneHot)\n",
      "P2_b_Outra Opção(OneHot)\n",
      "P2_b_Seguros ou Previdência(OneHot)\n",
      "P2_b_Setor Alimentício(OneHot)\n",
      "P2_b_Setor Automotivo(OneHot)\n",
      "P2_b_Setor Farmaceutico(OneHot)\n",
      "P2_b_Setor Imobiliário/ Construção Civil(OneHot)\n",
      "P2_b_Setor Público(OneHot)\n",
      "P2_b_Setor de Energia(OneHot)\n",
      "P2_b_Tecnologia/Fábrica de Software(OneHot)\n",
      "P2_b_Telecomunicação(OneHot)\n",
      "P2_b_Varejo(OneHot)\n",
      "P2_b_Área da Saúde(OneHot)\n",
      "P2_b_Área de Consultoria(OneHot)\n",
      "P2_b_nan(OneHot)\n",
      "P2_e_Diretor/VP(OneHot)\n",
      "P2_e_Gerente/Head(OneHot)\n",
      "P2_e_Supervisor/Coordenador(OneHot)\n",
      "P2_e_Sócio ou C-level (CEO, CDO, CIO, CTO etc)(OneHot)\n",
      "P2_e_Team Leader/Tech Leader(OneHot)\n",
      "P2_e_nan(OneHot)\n",
      "P2_f_Analista de BI/BI Analyst(OneHot)\n",
      "P2_f_Analista de Dados/Data Analyst(OneHot)\n",
      "P2_f_Analista de Inteligência de Mercado/Market Intelligence(OneHot)\n",
      "P2_f_Analista de Negócios/Business Analyst(OneHot)\n",
      "P2_f_Analista de Suporte/Analista Técnico(OneHot)\n",
      "P2_f_Analytics Engineer(OneHot)\n",
      "P2_f_Cientista de Dados/Data Scientist(OneHot)\n",
      "P2_f_DBA/Administrador de Banco de Dados(OneHot)\n",
      "P2_f_Data Product Manager/ Product Manager (PM/APM/DPM/GPM/PO)(OneHot)\n",
      "P2_f_Desenvolvedor/ Engenheiro de Software/ Analista de Sistemas(OneHot)\n",
      "P2_f_Economista(OneHot)\n",
      "P2_f_Engenheiro de Dados/Arquiteto de Dados/Data Engineer/Data Architect(OneHot)\n",
      "P2_f_Engenheiro de Machine Learning/ML Engineer/AI Engineer(OneHot)\n",
      "P2_f_Estatístico(OneHot)\n",
      "P2_f_Outra Opção(OneHot)\n",
      "P2_f_Outras Engenharias (não inclui dev)(OneHot)\n",
      "P2_f_Professor/Pesquisador(OneHot)\n",
      "P2_f_nan(OneHot)\n",
      "P2_g_Júnior(OneHot)\n",
      "P2_g_Pleno(OneHot)\n",
      "P2_g_Sênior(OneHot)\n",
      "P2_g_nan(OneHot)\n",
      "P2_i_Mais de 10 anos(OneHot)\n",
      "P2_i_Menos de 1 ano(OneHot)\n",
      "P2_i_Não tenho experiência na área de dados(OneHot)\n",
      "P2_i_de 1 a 2 anos(OneHot)\n",
      "P2_i_de 3 a 4 anos(OneHot)\n",
      "P2_i_de 4 a 6 anos(OneHot)\n",
      "P2_i_de 5 a 6 anos(OneHot)\n",
      "P2_i_de 7 a 10 anos(OneHot)\n",
      "P2_i_nan(OneHot)\n",
      "P2_j_Mais de 10 anos(OneHot)\n",
      "P2_j_Menos de 1 ano(OneHot)\n",
      "P2_j_Não tive experiência na área de TI/Engenharia de Software antes de começar a trabalhar na área de dados(OneHot)\n",
      "P2_j_de 1 a 2 anos(OneHot)\n",
      "P2_j_de 3 a 4 anos(OneHot)\n",
      "P2_j_de 5 a 6 anos(OneHot)\n",
      "P2_j_de 7 a 10 anos(OneHot)\n",
      "P2_j_nan(OneHot)\n",
      "P2_r_Modelo 100% presencial(OneHot)\n",
      "P2_r_Modelo 100% remoto(OneHot)\n",
      "P2_r_Modelo híbrido com dias fixos de trabalho presencial(OneHot)\n",
      "P2_r_Modelo híbrido flexível (o funcionário tem liberdade para escolher quando estar no escritório presencialmente)(OneHot)\n",
      "P2_r_nan(OneHot)\n",
      "P1_l(OrdEnc)\n",
      "P2_e(OrdEnc)\n",
      "P2_g(OrdEnc)\n",
      "P2_i(OrdEnc)\n",
      "P2_j(OrdEnc)\n",
      "P2_r(OrdEnc)\n"
     ]
    }
   ],
   "source": [
    "# drop all columns with label starting with 'P3'\n",
    "df = df.drop(df.columns[df.columns.str.startswith('P3')], axis=1)\n",
    "\n",
    "# drop all columns with label starting with \"P4\", \"P5\", \"P6\", \"P7\", \"P8\"\n",
    "df = df.drop(df.columns[df.columns.str.startswith('P4')], axis=1)\n",
    "df = df.drop(df.columns[df.columns.str.startswith('P5')], axis=1)\n",
    "df = df.drop(df.columns[df.columns.str.startswith('P6')], axis=1)\n",
    "df = df.drop(df.columns[df.columns.str.startswith('P7')], axis=1)\n",
    "df = df.drop(df.columns[df.columns.str.startswith('P8')], axis=1)\n",
    "\n",
    "for col in df.columns:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 P0  P1_a P1_a_1       P1_b     P1_c P1_d  \\\n",
      "0  001b2d1qtli8t9z7oqgdhj001b2d4i0g    31  30-34  Masculino   Branca  Não   \n",
      "1  0026aa3fwd78u0026asg7456tfkjg2cs    30  30-34  Masculino   Branca  Não   \n",
      "2  00r21rb9pusd1b0v7ew00r21rw3dy69w    37  35-39   Feminino  Amarela  Não   \n",
      "3  00urm3jf2cek12w6ygue00urm3jzd17j    22  22-24  Masculino    Preta  Não   \n",
      "4  00v0az4g792svil00vn6y1kfm9hq8vy9    34  30-34  Masculino   Branca  Não   \n",
      "\n",
      "                                                P1_e  P1_e_1  P1_e_2  P1_e_3  \\\n",
      "0                                                NaN    True    True    True   \n",
      "1                                                NaN    True    True    True   \n",
      "2  Sim, acredito que a minha a experiência profis...   False   False    True   \n",
      "3  Não acredito que minha experiência profissiona...    True   False   False   \n",
      "4                                                NaN    True    True    True   \n",
      "\n",
      "   ...  P2_r_Modelo 100% remoto(OneHot)  \\\n",
      "0  ...                            False   \n",
      "1  ...                             True   \n",
      "2  ...                            False   \n",
      "3  ...                            False   \n",
      "4  ...                             True   \n",
      "\n",
      "  P2_r_Modelo híbrido com dias fixos de trabalho presencial(OneHot)  \\\n",
      "0                                              False                  \n",
      "1                                              False                  \n",
      "2                                              False                  \n",
      "3                                              False                  \n",
      "4                                              False                  \n",
      "\n",
      "   P2_r_Modelo híbrido flexível (o funcionário tem liberdade para escolher quando estar no escritório presencialmente)(OneHot)  \\\n",
      "0                                               True                                                                             \n",
      "1                                              False                                                                             \n",
      "2                                               True                                                                             \n",
      "3                                              False                                                                             \n",
      "4                                              False                                                                             \n",
      "\n",
      "   P2_r_nan(OneHot)  P1_l(OrdEnc)  P2_e(OrdEnc)  P2_g(OrdEnc)  P2_i(OrdEnc)  \\\n",
      "0             False             6            -1             2             3   \n",
      "1             False             3            -1             1             3   \n",
      "2             False             3            -1             0             2   \n",
      "3              True             2            -1            -1            -1   \n",
      "4             False             6            -1             0             1   \n",
      "\n",
      "   P2_j(OrdEnc)  P2_r(OrdEnc)  \n",
      "0             0            -1  \n",
      "1             3             0  \n",
      "2             1            -1  \n",
      "3            -1            -1  \n",
      "4             1             0  \n",
      "\n",
      "[5 rows x 171 columns]\n"
     ]
    }
   ],
   "source": [
    "# Display the first few rows of the dataframe to get an initial overview of the data.\n",
    "print(df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop sensitive columns\n",
    "# P0\n",
    "df = df.drop('P0', axis=1)\n",
    "# P1_a and P1_a_1\n",
    "df = df.drop('P1_a', axis=1)\n",
    "df = df.drop('P1_a_1', axis=1)\n",
    "# P1_b\n",
    "df = df.drop('P1_b', axis=1)\n",
    "# P1_c\n",
    "df = df.drop('P1_c', axis=1)\n",
    "# P1_d\n",
    "df = df.drop('P1_d', axis=1)\n",
    "# P1_e and P1_e_1 to P1_e_4\n",
    "df = df.drop('P1_e', axis=1)\n",
    "df = df.drop('P1_e_1', axis=1)\n",
    "df = df.drop('P1_e_2', axis=1)\n",
    "df = df.drop('P1_e_3', axis=1)\n",
    "df = df.drop('P1_e_4', axis=1)\n",
    "# P1_f and P1_f_1 to P1_f_9\n",
    "df = df.drop('P1_f', axis=1)\n",
    "df = df.drop('P1_f_1', axis=1)\n",
    "df = df.drop('P1_f_2', axis=1)\n",
    "df = df.drop('P1_f_3', axis=1)\n",
    "df = df.drop('P1_f_4', axis=1)\n",
    "df = df.drop('P1_f_5', axis=1)\n",
    "df = df.drop('P1_f_6', axis=1)\n",
    "df = df.drop('P1_f_7', axis=1)\n",
    "df = df.drop('P1_f_8', axis=1)\n",
    "df = df.drop('P1_f_9', axis=1)\n",
    "# P1_i and P1_i_1 to P1_i_2\n",
    "df = df.drop('P1_i', axis=1)\n",
    "df = df.drop('P1_i_1', axis=1)\n",
    "df = df.drop('P1_i_2', axis=1)\n",
    "# P1_j\n",
    "df = df.drop('P1_j', axis=1)\n",
    "# P1_k\n",
    "df = df.drop('P1_k', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop irrelevant columns\n",
    "# P2_l\n",
    "df = df.drop('P2_l', axis=1)\n",
    "# P2_n\n",
    "df = df.drop('P2_n', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P2_e    83.071982\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Calculate the percentage of missing values for each column\n",
    "missing_percentage = df.isnull().sum() * 100 / len(df)\n",
    "\n",
    "# Print columns with more than 50% missing values\n",
    "print(missing_percentage[missing_percentage > 50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    Não é gestor\n",
      "1    Não é gestor\n",
      "2    Não é gestor\n",
      "3    Não é gestor\n",
      "4    Não é gestor\n",
      "Name: P2_e, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Fill missing values with \"Não é gerente\"\n",
    "df['P2_e'] = df['P2_e'].fillna(\"Não é gestor\")\n",
    "\n",
    "# print the first few rows of P2_a to check if the missing values are filled\n",
    "print(df['P2_e'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select numerical and categorical columns\n",
    "numerical_cols = df.select_dtypes(include=['number']).columns\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Delete rows with missing values in numerical columns\n",
    "df = df.dropna(subset=numerical_cols)\n",
    "\n",
    "# delete rows with missing values in categorical columns\n",
    "df = df.dropna(subset=categorical_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use IRQ method to detect and remove outliers\n",
    "Q1 = df[numerical_cols].quantile(0.25)\n",
    "Q3 = df[numerical_cols].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "for col in numerical_cols:\n",
    "    df[col] = df[col].clip(lower_bound[col], upper_bound[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3766, 782)\n"
     ]
    }
   ],
   "source": [
    "# Identify categorical features and convert them into numerical representations using one-hot encoding\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "\n",
    "df = pd.get_dummies(df, columns=categorical_cols)\n",
    "\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the cleaned data to a new csv file\n",
    "df.to_csv('explore/trimmed_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
